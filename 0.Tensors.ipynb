{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.10.0+cu113'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check pytorch version\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1160, 0.2202, 0.0753])\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(3) #creating a random torch tensor\n",
    "print(x)\n",
    "print(type(x)) #In pytorch, everything is a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available() #check CUDA availabilty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3.6013e-43, 0.0000e+00])\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "x = torch.empty(2) #creating an empty tensor, values are not initialised yet\n",
    "print(x)\n",
    "print(type(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0000, 1.8750, 0.0000, 0.0000])\n"
     ]
    }
   ],
   "source": [
    "x = torch.empty(4) #empty tensor, values are not initialised yet\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000e+00, 6.8664e-44, 6.5991e-10],\n",
      "        [3.2502e+21, 1.3435e-05, 1.7375e-04]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.empty(2,3) #2D \n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1.0653e-38, 1.0194e-38, 8.4490e-39],\n",
      "         [1.0469e-38, 9.3674e-39, 9.9184e-39],\n",
      "         [8.7245e-39, 9.2755e-39, 8.9082e-39]],\n",
      "\n",
      "        [[9.9184e-39, 8.4490e-39, 9.6429e-39],\n",
      "         [1.0653e-38, 1.0469e-38, 4.2246e-39],\n",
      "         [1.0378e-38, 9.6429e-39, 9.2755e-39]]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.empty(2,3,3) #3D\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0911, 0.6132])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(2) #random tensor\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9635, 0.2956, 0.5240],\n",
      "        [0.2020, 0.3476, 0.6713]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(2,3) #random tensor\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros(2,2) #all zero tensor\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(2,3) #all one tensor, by default the data type is float\n",
    "print(x)\n",
    "print(x.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1, 1],\n",
      "        [1, 1, 1]], dtype=torch.int32)\n",
      "torch.int32\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(2,3,dtype=torch.int) #setting the data type of the tensor elements\n",
    "print(x)\n",
    "print(x.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]], dtype=torch.float64)\n",
      "torch.float64\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(2,3,dtype=torch.double) \n",
    "print(x)\n",
    "print(x.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(2,3,dtype=torch.float) \n",
    "print(x)\n",
    "print(x.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "torch.float32\n",
      "torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(2,3,dtype=torch.float) \n",
    "print(x)\n",
    "print(x.dtype) # Data type of the tensor elements\n",
    "print(x.size()) # Size of the tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0000, 2.0000, 3.0000, 4.0000, 5.8000])\n"
     ]
    }
   ],
   "source": [
    "y = [1,2,3,4,5.8]\n",
    "x = torch.tensor(y)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(2,2)\n",
    "y = torch.rand(2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.1849, 0.4369],\n",
      "        [1.7800, 1.2907]])\n",
      "tensor([[2.1849, 0.4369],\n",
      "        [1.7800, 1.2907]])\n",
      "tensor([[2.1849, 0.4369],\n",
      "        [1.7800, 1.2907]])\n",
      "tensor([[-3.8051, -0.8544],\n",
      "        [-3.2372, -2.2460]])\n",
      "tensor([[-3.8051, -0.8544],\n",
      "        [-3.2372, -2.2460]])\n",
      "tensor([[3.8051, 0.8544],\n",
      "        [3.2372, 2.2460]])\n",
      "tensor([[-5.4253, -1.2719],\n",
      "        [-4.6945, -3.2014]])\n"
     ]
    }
   ],
   "source": [
    "#tensor operations\n",
    "z = x+y #simple addition, element wise addition\n",
    "print(z)\n",
    "\n",
    "z = torch.add(x,y) #does the same as above\n",
    "print(z)\n",
    "\n",
    "y.add_(x)#in place addition, every function with \"_\" will do an inplace operation and will modify the original one\n",
    "print(y)\n",
    "\n",
    "z=x-y\n",
    "print(z)\n",
    "z = torch.sub(x,y) #x minus y (x-y)\n",
    "print(z)\n",
    "y.sub_(x) #y minus x (y-x)\n",
    "print(y)\n",
    "x.sub_(y) #x minus y (x-y)\n",
    "print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1750, 0.1422],\n",
      "        [0.0339, 0.1172]])\n",
      "tensor([[0.1750, 0.1422],\n",
      "        [0.0339, 0.1172]])\n",
      "tensor([[0.1750, 0.1422],\n",
      "        [0.0339, 0.1172]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(2,2)\n",
    "y = torch.rand(2,2)\n",
    "\n",
    "z = x*y #element wise multiplication\n",
    "print(z)\n",
    "z = torch.mul(x,y) #element wise multiplication\n",
    "print(z)\n",
    "y.mul_(x) #functions with underscore \"_\" are inplace operations\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.1872, 1.2088],\n",
      "        [1.3003, 0.4593]])\n",
      "tensor([[1.1872, 1.2088],\n",
      "        [1.3003, 0.4593]])\n",
      "tensor([[0.8423, 0.8273],\n",
      "        [0.7690, 2.1773]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(2,2)\n",
    "y = torch.rand(2,2)\n",
    "\n",
    "z = x/y #element wise division\n",
    "print(z)\n",
    "z = torch.div(x,y)\n",
    "print(z)\n",
    "y.div_(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5966, 0.4813, 0.4252],\n",
      "        [0.7147, 0.5158, 0.1239],\n",
      "        [0.0890, 0.9355, 0.5944],\n",
      "        [0.2341, 0.8854, 0.8409],\n",
      "        [0.3437, 0.8908, 0.2324]])\n"
     ]
    }
   ],
   "source": [
    "#Tensor Slicing\n",
    "x = torch.rand(5,3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5966, 0.7147, 0.0890, 0.2341, 0.3437])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.8793, 0.5474, 0.9924, 0.6182, 0.1334])\n",
      "tensor([0.8816, 0.9787, 0.1730, 0.6370, 0.5224])\n",
      "tensor([0.8793, 0.8816, 0.8957])\n",
      "tensor(0.9787)\n"
     ]
    }
   ],
   "source": [
    "print(x[:,0]) #all rows, first column\n",
    "print(x[:,1]) #all rows, second column\n",
    "print(x[0,:]) #first row, all columns\n",
    "\n",
    "print(x[1,1]) #element at 1,1 as tensor , not as data, need to use item() to acess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9787)\n",
      "0.9787145256996155\n"
     ]
    }
   ],
   "source": [
    "print(x[1,1]) #element at 1,1, this gives tensor\n",
    "print(x[1,1].item()) #this gives actual value and not tensor, this works only when there is a single element in the tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5598, 0.5358, 0.0634, 0.5418],\n",
      "        [0.6733, 0.2564, 0.2451, 0.5409],\n",
      "        [0.4438, 0.0231, 0.0020, 0.0319],\n",
      "        [0.1917, 0.3494, 0.6010, 0.7252]])\n",
      "tensor([0.5598, 0.5358, 0.0634, 0.5418, 0.6733, 0.2564, 0.2451, 0.5409, 0.4438,\n",
      "        0.0231, 0.0020, 0.0319, 0.1917, 0.3494, 0.6010, 0.7252])\n",
      "tensor([[0.5598, 0.5358, 0.0634, 0.5418, 0.6733, 0.2564, 0.2451, 0.5409],\n",
      "        [0.4438, 0.0231, 0.0020, 0.0319, 0.1917, 0.3494, 0.6010, 0.7252]])\n",
      "tensor([[0.5598, 0.5358, 0.0634, 0.5418, 0.6733, 0.2564, 0.2451, 0.5409],\n",
      "        [0.4438, 0.0231, 0.0020, 0.0319, 0.1917, 0.3494, 0.6010, 0.7252]])\n",
      "tensor([[0.5598, 0.5358, 0.0634, 0.5418, 0.6733, 0.2564, 0.2451, 0.5409],\n",
      "        [0.4438, 0.0231, 0.0020, 0.0319, 0.1917, 0.3494, 0.6010, 0.7252]])\n"
     ]
    }
   ],
   "source": [
    "#reshaping a tensor\n",
    "x = torch.rand(4,4)\n",
    "print(x)\n",
    "y = x.view(16) #total number of elements must match\n",
    "print(y)\n",
    "y = x.view(2,8)\n",
    "print(y)\n",
    "y = x.view(-1,8) #automatically detects the argument at \"-1\", if we cannot calculate the total number of elements\n",
    "print(y)\n",
    "y = x.view(2,-1)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n",
      "[1. 1. 1. 1. 1.]\n",
      "type of a <class 'torch.Tensor'>\n",
      "type of b <class 'numpy.ndarray'>\n",
      "tensor([2., 2., 2., 2., 2.])\n",
      "[2. 2. 2. 2. 2.]\n",
      "[1. 1. 1. 1. 1.]\n",
      "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n",
      "[2. 2. 2. 2. 2.]\n",
      "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "#numpy to tensor and vice versa\n",
    "import numpy as np\n",
    "\n",
    "a = torch.ones(5)\n",
    "print(a)\n",
    "\n",
    "b = a.numpy() #tensor to a numpy array\n",
    "print(b)\n",
    "print(\"type of a\",type(a))\n",
    "print(\"type of b\",type(b))\n",
    "\n",
    "### if the tensor is on cpu and not gpu, both objects will share same memory location, changing one will change another\n",
    "a.add_(1)\n",
    "print(a)\n",
    "print(b)\n",
    "\n",
    "\n",
    "a = np.ones(5)\n",
    "print(a)\n",
    "b = torch.from_numpy(a)\n",
    "print(b)\n",
    "\n",
    "### if the tensor is on cpu and not gpu, both objects will share same memory location, changing one will change another\n",
    "a +=1\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 2. 2.]\n",
      "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n",
      "tensor([3., 3., 3., 3., 3.])\n",
      "[3. 3. 3. 3. 3.]\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    #all of the following variables are on CPU and not on GPU, both objects (torch tensor and numpy array) share same memory location\n",
    "    a = np.ones(5)\n",
    "    k = torch.from_numpy(a)\n",
    "    c = torch.ones(5)\n",
    "    f = c.numpy()\n",
    "\n",
    "#Changing one object will result in changing both objects, as they share the same memory location\n",
    "a+=1\n",
    "print(a)\n",
    "print(k)\n",
    "f+=2\n",
    "print(c)\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.device(\"cuda\") #accessing torch CUDA / GPU device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Abhinav Reddy Nimma\\Desktop\\Artificial Intelligence\\PyTorch\\0.Tensors.ipynb Cell 30'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Abhinav%20Reddy%20Nimma/Desktop/Artificial%20Intelligence/PyTorch/0.Tensors.ipynb#ch0000030?line=3'>4</a>\u001b[0m     k \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mfrom_numpy(a)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Abhinav%20Reddy%20Nimma/Desktop/Artificial%20Intelligence/PyTorch/0.Tensors.ipynb#ch0000030?line=4'>5</a>\u001b[0m     c \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mones(\u001b[39m5\u001b[39m,device\u001b[39m=\u001b[39mdevice)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Abhinav%20Reddy%20Nimma/Desktop/Artificial%20Intelligence/PyTorch/0.Tensors.ipynb#ch0000030?line=5'>6</a>\u001b[0m     f \u001b[39m=\u001b[39m c\u001b[39m.\u001b[39;49mnumpy()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Abhinav%20Reddy%20Nimma/Desktop/Artificial%20Intelligence/PyTorch/0.Tensors.ipynb#ch0000030?line=7'>8</a>\u001b[0m a\u001b[39m+\u001b[39m\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Abhinav%20Reddy%20Nimma/Desktop/Artificial%20Intelligence/PyTorch/0.Tensors.ipynb#ch0000030?line=8'>9</a>\u001b[0m \u001b[39mprint\u001b[39m(a)\n",
      "\u001b[1;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    a = np.ones(5)\n",
    "    k = torch.from_numpy(a)\n",
    "    c = torch.ones(5,device=device) # Variable created on GPU\n",
    "    f = c.numpy() #Converting CUDA tensor to numpy directly, will result in an error\n",
    "\n",
    "a+=1\n",
    "print(a)\n",
    "print(k)\n",
    "f+=1\n",
    "print(c)\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 2. 2.]\n",
      "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n",
      "modifying CPU array\n",
      "tensor([1., 1., 1., 1., 1.], device='cuda:0')\n",
      "tensor([2., 2., 2., 2., 2.])\n",
      "[2. 2. 2. 2. 2.]\n",
      "modifying CPU tensor\n",
      "tensor([1., 1., 1., 1., 1.], device='cuda:0')\n",
      "tensor([3., 3., 3., 3., 3.])\n",
      "[3. 3. 3. 3. 3.]\n",
      "modifying GPU tensor\n",
      "tensor([6., 6., 6., 6., 6.], device='cuda:0')\n",
      "tensor([3., 3., 3., 3., 3.])\n",
      "[3. 3. 3. 3. 3.]\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    a = np.ones(5) #numpy array\n",
    "    k = torch.from_numpy(a) #converting numpy array to torch tensot\n",
    "\n",
    "    c = torch.ones(5,device=device) #now the tensor is created on the GPU\n",
    "    cc = c.cpu() #we need to copy the tensor from gpu to cpu memory first, numpy can only handle cpu tensors\n",
    "    cc = c.to(\"cpu\") #does the same as above line\n",
    "    f = cc.numpy()\n",
    "\n",
    "    x = torch.ones(5)\n",
    "    y = x.to(device) #move to gpu\n",
    "\n",
    "a+=1\n",
    "print(a)\n",
    "print(k) #both share same memory location, hence changing one would result in changing both\n",
    "\n",
    "print(\"modifying CPU array\")\n",
    "f+=1 #cc,f share same memory location. changing one would result in chaning both, but doesnot effect GPU variable c\n",
    "print(c) #GPU tensor\n",
    "print(cc) #CPU tensor\n",
    "print(f) # CPU array\n",
    "\n",
    "print(\"modifying CPU tensor\")\n",
    "cc+=1 #cc,f share same memory location. changing one would result in chaning both, but doesnot effect GPU variable c\n",
    "print(c) #GPU tensor\n",
    "print(cc) #CPU tensor\n",
    "print(f) # CPU array\n",
    "\n",
    "print(\"modifying GPU tensor\")\n",
    "c.add_(5) #changing C does not effect CC & f\n",
    "print(c)\n",
    "print(cc)\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n",
      "tensor([1., 1., 1., 1., 1.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(5,) \n",
    "print(x)\n",
    "y = torch.ones(5,requires_grad=True) #this means that pytorch will need to calculate gradient for this tensor in later steps\n",
    "#for variables we need to optimise, we need gradients, hence we need to specify reuires_grad\n",
    "print(y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "83bec4cd18966703d39e3fd8209371b7574445e5ac2dfe27a80cb33e9b531167"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
