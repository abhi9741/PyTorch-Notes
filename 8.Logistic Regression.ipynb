{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Design the model - input size, output size, forward pass\n",
    "# loss and optimiser\n",
    "# training loop - forward, backward, weight updation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn as nn\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler #to scale\n",
    "from sklearn.model_selection import train_test_split #to split th dataset into train and test\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc = datasets.load_breast_cancer() #binary classification problem\n",
    "x,y = bc.data, bc.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data samples - 569, Number of features - 30\n"
     ]
    }
   ],
   "source": [
    "n_sample, n_features = x.shape\n",
    "print(f\"Number of data samples - {n_sample}, Number of features - {n_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=47)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scaling the feature\n",
    "sc = StandardScaler() #zero mean, unit variance (do this when dealing with logistic regression, why?)\n",
    "\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.from_numpy(x_train.astype(np.float32))\n",
    "y_train = torch.from_numpy(y_train.astype(np.float32))\n",
    "x_test = torch.from_numpy(x_test.astype(np.float32))\n",
    "y_test = torch.from_numpy(y_test.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape y to column vector\n",
    "y_train = y_train.view(-1,1)\n",
    "y_test = y_test.view(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train - torch.Size([455, 30])\n",
      "Y train - torch.Size([455, 1])\n",
      "X test - torch.Size([114, 30])\n",
      "Y test - torch.Size([114, 1])\n"
     ]
    }
   ],
   "source": [
    "#check the dimensions of datasets\n",
    "print(f\"X train - {x_train.shape}\")\n",
    "print(f\"Y train - {y_train.shape}\")\n",
    "print(f\"X test - {x_test.shape}\")\n",
    "print(f\"Y test - {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression function - f = wx+b, sigmoid at the end\n",
    "\n",
    "class LogisticReg(nn.Module):\n",
    "    def __init__(self,n_features_input):\n",
    "        super(LogisticReg,self).__init__()\n",
    "        self.lin = nn.Linear(in_features=n_features_input,out_features=1)\n",
    "\n",
    "    def forward(self,x):\n",
    "        y_pred = torch.sigmoid(self.lin(x))\n",
    "        return y_pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss at epoch 1 is 0.65\n",
      "loss at epoch 11 is 0.53\n",
      "loss at epoch 21 is 0.45\n",
      "loss at epoch 31 is 0.40\n",
      "loss at epoch 41 is 0.36\n",
      "loss at epoch 51 is 0.33\n",
      "loss at epoch 61 is 0.31\n",
      "loss at epoch 71 is 0.29\n",
      "loss at epoch 81 is 0.27\n",
      "loss at epoch 91 is 0.26\n",
      "loss at epoch 101 is 0.25\n",
      "loss at epoch 111 is 0.24\n",
      "loss at epoch 121 is 0.23\n",
      "loss at epoch 131 is 0.22\n",
      "loss at epoch 141 is 0.22\n",
      "loss at epoch 151 is 0.21\n",
      "loss at epoch 161 is 0.21\n",
      "loss at epoch 171 is 0.20\n",
      "loss at epoch 181 is 0.20\n",
      "loss at epoch 191 is 0.19\n"
     ]
    }
   ],
   "source": [
    "model = LogisticReg(x_train.shape[1])\n",
    "loss_func = nn.BCELoss() #binary cross entropy loss, why??\n",
    "learning_rate = 0.01\n",
    "optimiser = torch.optim.SGD(model.parameters(),lr = learning_rate)\n",
    "\n",
    "epochs = 200\n",
    "\n",
    "for epoch in range(epochs) :\n",
    "    #forward pass\n",
    "    y_pred = model(x_train)\n",
    "    loss = loss_func(y_pred,y_train)\n",
    "\n",
    "    #backward oass\n",
    "    loss.backward()\n",
    "\n",
    "    #weight updation\n",
    "    optimiser.step()\n",
    "    optimiser.zero_grad()\n",
    "\n",
    "    if epoch%10 ==0:\n",
    "        print(f\"loss at epoch {epoch+1} is {loss.item():.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy is 0.9561\n"
     ]
    }
   ],
   "source": [
    "#model evaluation\n",
    "\n",
    "with torch.no_grad() : #we dont want evaluatio to be part of computation graph\n",
    "    y_pred = model(x_test)\n",
    "    \n",
    "    #converting sigmoid outputs into zero and one\n",
    "    y_pred_classes = y_pred.round() #less than 0.5, class 0. else class 1\n",
    "\n",
    "    acc = y_pred_classes.eq(y_test).sum() / float(y_test.shape[0]) #eq is equals\n",
    "    print(f\"Model accuracy is {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try to make it work for test train validation, plot the loss history, accuracy history etc stuff "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "83bec4cd18966703d39e3fd8209371b7574445e5ac2dfe27a80cb33e9b531167"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
